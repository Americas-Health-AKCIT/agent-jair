{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoaoC\\AppData\\Local\\Temp\\ipykernel_39776\\3919829950.py:87: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_requisicao = pd.read_csv(PATH_REQUISICAO, encoding='latin1')\n",
      "C:\\Users\\JoaoC\\AppData\\Local\\Temp\\ipykernel_39776\\3919829950.py:89: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_itens_nome = pd.read_csv(PATH_ITENS_NOME, encoding='latin1')\n",
      "C:\\Users\\JoaoC\\AppData\\Local\\Temp\\ipykernel_39776\\3919829950.py:90: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_beneficiario = pd.read_csv(PATH_BENEFICIARIO, encoding='latin1')\n",
      "c:\\Users\\JoaoC\\Nextcloud\\Projetos\\AmericasHealth\\agente-jair-autorizacao\\modelo_ml_tradicional\\transformers.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X['TITULARIDADE'] = X['TITULARIDADE'].replace({'N': 0, 'S': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (311666, 232)\n",
      "y_train shape: (311666,)\n",
      "X_test shape: (24329, 232)\n",
      "y_test shape: (24329,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from modelo_ml_tradicional.transformers import (\n",
    "    DateDifferenceTransformer,\n",
    "    DropColumnsTransformer,\n",
    "    BinaryNumericTransformer,\n",
    "    Word2VecTransformer,\n",
    "    StatusItemMapper,\n",
    "    OneHotEncodingTransformer\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Configurações\n",
    "# =============================================================================\n",
    "PATH_REQUISICAO = r'modelo_ml_tradicional/Evah/OMNI_DADOS_REQUISICAO.csv'\n",
    "PATH_ITENS = r'modelo_ml_tradicional/Evah/OMNI_DADOS_REQUISICAO_ITEM.csv'\n",
    "PATH_ITENS_NOME = r'modelo_ml_tradicional/Evah/OMNI_DADOS_ITEM.csv'\n",
    "PATH_BENEFICIARIO = r'modelo_ml_tradicional/Evah/OMNI_DADOS_BENEFICIARIO.csv'\n",
    "PATH_PRESTADOR = r'modelo_ml_tradicional/Evah/OMNI_DADOS_PRESTADOR.csv'\n",
    "\n",
    "STATUS_ITEM_REMOVER = [\n",
    "    'Liberado pelo sistema', \n",
    "    'Em desacordo com os critï¿½rios tï¿½cnicos', \n",
    "    'Em anï¿½lise'\n",
    "]\n",
    "\n",
    "MAP_STATUS_ITEM = {\n",
    "    'Liberado pelo usuï¿½rio': 'Liberado pelo usuário',\n",
    "    'Nï¿½o liberado': 'Não liberado'\n",
    "}\n",
    "\n",
    "STATUS_ITEM_NUM_MAP = {\n",
    "    'Liberado pelo usuário': 1,\n",
    "    'Não liberado': 0\n",
    "}\n",
    "\n",
    "COLUNAS_PARA_REMOVER = [\n",
    "    'DS_STATUS_REQUISICAO', \n",
    "    'DT_ATUALIZACAO_y', \n",
    "    'ID_BENEFICIARIO', \n",
    "    'DT_REQUISICAO', \n",
    "    'DT_FIM_ANALISE', \n",
    "    'DT_ATUALIZACAO', \n",
    "    'CD_ITEM', \n",
    "    'ID_GUIA_PRINCIPAL', \n",
    "    'ID_ITEM', \n",
    "    'DS_TIPO_ACOMODACAO', \n",
    "    'DT_ENTRADA_HOSPITAL',\n",
    "    'CD_UNIDADE_MEDIDA',\n",
    "    'DS_CLASSIFICACAO_2',\n",
    "    'DS_CLASSIFICACAO_3',\n",
    "    'DS_CLASSIFICACAO_BI',\n",
    "    'ID_PRESTADOR', \n",
    "    'ID_PROFISSIONAL', \n",
    "    'ID_TITULAR', \n",
    "    'ID_PLANO',\n",
    "    'ID_ESTIPULANTE',\n",
    "    'APOLICE',\n",
    "    'DATA_INICIO_VIGENCIA',\n",
    "    'CARENCIA',\n",
    "    'NM_BENEFICIARIO',\n",
    "    'NR_CPF',\n",
    "    'PARENTESCO',\n",
    "    'SEXO',\n",
    "    'ESTADO_CIVIL',\n",
    "    'EMAIL',\n",
    "    'DDD_TELEFONE',\n",
    "    'NR_TELEFONE'\n",
    "]\n",
    "\n",
    "COLUNAS_PARA_CODIFICAR = [\n",
    "    'DS_TIPO_GUIA', \n",
    "    'DS_CARATER_ATENDIMENTO', \n",
    "    'DS_TIPO_INTERNACAO', \n",
    "    'DS_CBO_PROFISSIONAL', \n",
    "    'DS_REGIME_INTERNACAO', \n",
    "    'DS_TIPO_SADT', \n",
    "    'DS_TIPO_CONSULTA', \n",
    "    'DS_TIPO_ITEM', \n",
    "    'DS_CLASSIFICACAO_1'\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# Funções Auxiliares\n",
    "# =============================================================================\n",
    "def carregar_dados():\n",
    "    df_requisicao = pd.read_csv(PATH_REQUISICAO, encoding='latin1')\n",
    "    df_itens = pd.read_csv(PATH_ITENS, encoding='latin1')\n",
    "    df_itens_nome = pd.read_csv(PATH_ITENS_NOME, encoding='latin1')\n",
    "    df_beneficiario = pd.read_csv(PATH_BENEFICIARIO, encoding='latin1')\n",
    "    df_prestador = pd.read_csv(PATH_PRESTADOR, encoding='latin1')\n",
    "    return df_requisicao, df_itens, df_itens_nome, df_beneficiario, df_prestador\n",
    "\n",
    "def preparar_merged(df_requisicao, df_itens, df_beneficiario, df_itens_nome):\n",
    "    df_filtrado = pd.merge(df_requisicao, df_beneficiario, on='ID_BENEFICIARIO', how='left')\n",
    "    df_combinado = pd.merge(df_itens, df_filtrado, on='ID_REQUISICAO', how='left')\n",
    "    # Remover linhas com DS_STATUS_REQUISICAO nulo\n",
    "    df_combinado = df_combinado.dropna(subset=['DS_STATUS_REQUISICAO'])\n",
    "    # Remover itens com status não desejados\n",
    "    df_combinado = df_combinado[~df_combinado['DS_STATUS_ITEM'].isin(STATUS_ITEM_REMOVER)]\n",
    "    # Ajustar acentuação\n",
    "    df_combinado['DS_STATUS_ITEM'] = df_combinado['DS_STATUS_ITEM'].replace(MAP_STATUS_ITEM)\n",
    "    # Mesclar com nomes de itens\n",
    "    df_merged = pd.merge(df_combinado, df_itens_nome, on='ID_ITEM', how='left')\n",
    "    return df_merged\n",
    "\n",
    "def filtrar_dados_por_mes(df, ano=2024, mes=8):\n",
    "    df['DT_ATUALIZACAO_x'] = pd.to_datetime(df['DT_ATUALIZACAO_x'], format='%d/%m/%y', errors='coerce')\n",
    "    data_inicio = pd.to_datetime(f'{ano}-{mes:02d}-01')\n",
    "    data_fim = (data_inicio + pd.offsets.MonthEnd(1))\n",
    "\n",
    "    df_filtrado_mes = df[(df['DT_ATUALIZACAO_x'] >= data_inicio) & (df['DT_ATUALIZACAO_x'] <= data_fim)]\n",
    "    df_excluido_mes = df[~df['DT_ATUALIZACAO_x'].between(data_inicio, data_fim)]\n",
    "    return df_filtrado_mes, df_excluido_mes\n",
    "\n",
    "def main(ano=2024, mes=8):\n",
    "    # Carrega dados\n",
    "    df_requisicao, df_itens, df_itens_nome, df_beneficiario, df_prestador = carregar_dados()\n",
    "    \n",
    "    # Merge inicial\n",
    "    df_merged = preparar_merged(df_requisicao, df_itens, df_beneficiario, df_itens_nome)\n",
    "    \n",
    "    # Cria a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('date_diff', DateDifferenceTransformer()),\n",
    "        ('drop_cols', DropColumnsTransformer(COLUNAS_PARA_REMOVER)),\n",
    "        ('binary_numeric', BinaryNumericTransformer()),\n",
    "        ('word2vec', Word2VecTransformer(text_col='DS_ITEM')),\n",
    "        ('status_map', StatusItemMapper(STATUS_ITEM_NUM_MAP)),\n",
    "        ('one_hot', OneHotEncodingTransformer(COLUNAS_PARA_CODIFICAR)),\n",
    "        ('drop_ds_item', DropColumnsTransformer(['DS_ITEM'])),\n",
    "    ])\n",
    "    \n",
    "    # Aplica a pipeline\n",
    "    df_final = pipeline.fit_transform(df_merged)\n",
    "    \n",
    "    # Remove valores nulos (se houver)\n",
    "    df_final = df_final.dropna()\n",
    "    \n",
    "    # Filtra dados para o mês/ano desejado\n",
    "    df_filtrado_mes, df_excluido_mes = filtrar_dados_por_mes(df_final, ano=ano, mes=mes)\n",
    "    \n",
    "    # Prepara X e y\n",
    "    # Remove colunas de identificação e data do conjunto final\n",
    "    df_filtrado_mes = df_filtrado_mes.drop(columns=['ID_REQUISICAO_ITEM', 'DT_ATUALIZACAO_x', 'ID_REQUISICAO'], errors='ignore')\n",
    "    df_excluido_mes = df_excluido_mes.drop(columns=['ID_REQUISICAO_ITEM', 'DT_ATUALIZACAO_x', 'ID_REQUISICAO'], errors='ignore')\n",
    "    \n",
    "    X_train = df_excluido_mes.drop(columns=['DS_STATUS_ITEM'])\n",
    "    y_train = df_excluido_mes['DS_STATUS_ITEM']\n",
    "    \n",
    "    X_test = df_filtrado_mes.drop(columns=['DS_STATUS_ITEM'])\n",
    "    y_test = df_filtrado_mes['DS_STATUS_ITEM']\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train, y_train, X_test, y_test = main(ano=2024, mes=8)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoaoC\\AppData\\Local\\Temp\\ipykernel_39776\\3919829950.py:87: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_requisicao = pd.read_csv(PATH_REQUISICAO, encoding='latin1')\n",
      "C:\\Users\\JoaoC\\AppData\\Local\\Temp\\ipykernel_39776\\3919829950.py:89: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_itens_nome = pd.read_csv(PATH_ITENS_NOME, encoding='latin1')\n",
      "C:\\Users\\JoaoC\\AppData\\Local\\Temp\\ipykernel_39776\\3919829950.py:90: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_beneficiario = pd.read_csv(PATH_BENEFICIARIO, encoding='latin1')\n",
      "c:\\Users\\JoaoC\\Nextcloud\\Projetos\\AmericasHealth\\agente-jair-autorizacao\\modelo_ml_tradicional\\transformers.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X['TITULARIDADE'] = X['TITULARIDADE'].replace({'N': 0, 'S': 1})\n"
     ]
    }
   ],
   "source": [
    "ano = 2024\n",
    "mes = 8\n",
    "\n",
    "df_requisicao, df_itens, df_itens_nome, df_beneficiario, df_prestador = carregar_dados()\n",
    "\n",
    "# Merge inicial\n",
    "df_merged = preparar_merged(df_requisicao, df_itens, df_beneficiario, df_itens_nome)\n",
    "\n",
    "# Cria a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('date_diff', DateDifferenceTransformer()),\n",
    "    ('drop_cols', DropColumnsTransformer(COLUNAS_PARA_REMOVER)),\n",
    "    ('binary_numeric', BinaryNumericTransformer()),\n",
    "    ('word2vec', Word2VecTransformer(text_col='DS_ITEM')),\n",
    "    ('status_map', StatusItemMapper(STATUS_ITEM_NUM_MAP)),\n",
    "    ('one_hot', OneHotEncodingTransformer(COLUNAS_PARA_CODIFICAR)),\n",
    "    ('drop_ds_item', DropColumnsTransformer(['DS_ITEM'])),\n",
    "])\n",
    "\n",
    "# Aplica a pipeline\n",
    "df_final = pipeline.fit_transform(df_merged)\n",
    "\n",
    "# Remove valores nulos (se houver)\n",
    "df_final = df_final.dropna()\n",
    "\n",
    "# Filtra dados para o mês/ano desejado\n",
    "df_filtrado_mes, df_excluido_mes = filtrar_dados_por_mes(df_final, ano=ano, mes=mes)\n",
    "\n",
    "# Prepara X e y\n",
    "# Remove colunas de identificação e data do conjunto final\n",
    "df_filtrado_mes = df_filtrado_mes.drop(columns=['ID_REQUISICAO_ITEM', 'DT_ATUALIZACAO_x', 'ID_REQUISICAO'], errors='ignore')\n",
    "df_excluido_mes = df_excluido_mes.drop(columns=['ID_REQUISICAO_ITEM', 'DT_ATUALIZACAO_x', 'ID_REQUISICAO'], errors='ignore')\n",
    "\n",
    "X_train = df_excluido_mes.drop(columns=['DS_STATUS_ITEM'])\n",
    "y_train = df_excluido_mes['DS_STATUS_ITEM']\n",
    "\n",
    "X_test = df_filtrado_mes.drop(columns=['DS_STATUS_ITEM'])\n",
    "y_test = df_filtrado_mes['DS_STATUS_ITEM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_merged.groupby(df_merged['ID_REQUISICAO']).count().sort_values(by='ID_REQUISICAO_ITEM', ascending=False).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41917332,\n",
       " 41918527,\n",
       " 41894852,\n",
       " 41911143,\n",
       " 41904993,\n",
       " 41911885,\n",
       " 41904998,\n",
       " 41918592,\n",
       " 41911604,\n",
       " 41898510]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a['ID_REQUISICAO_ITEM'] == 1].head(10)['ID_REQUISICAO'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "41917332\n",
    "41918527\n",
    "41894852\n",
    " 41911143,\n",
    " 41904993,\n",
    " 41911885,\n",
    " 41904998,\n",
    " 41918592,\n",
    " 41911604,\n",
    " 41898510]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
